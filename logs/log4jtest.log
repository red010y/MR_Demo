2020-04-11 21:38:24 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:38:26 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:38:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:38:27 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0001
2020-04-11 21:38:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-04-11 21:38:27 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0001
2020-04-11 21:39:12 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:39:22 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:39:23 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:39:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0002
2020-04-11 21:39:24 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0002
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 21:39:24 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 21:39:27 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0002
2020-04-11 21:39:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0002/
2020-04-11 21:39:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0002
2020-04-11 21:39:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0002 running in uber mode : false
2020-04-11 21:39:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 21:39:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0002 failed with state FAILED due to: Application application_1586570645554_0002 failed 2 times due to AM Container for appattempt_1586570645554_0002_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0002_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 21:39:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 21:50:54 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:50:55 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:50:56 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:50:56 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0003
2020-04-11 21:50:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0003
2020-04-11 21:51:36 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:51:37 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:51:38 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:51:38 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0004
2020-04-11 21:51:38 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0004
2020-04-11 21:52:45 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:52:46 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:52:46 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:52:46 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0005
2020-04-11 21:52:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0005
2020-04-11 21:55:19 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:55:20 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:55:21 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:55:21 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0006
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0006
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0006
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0006/
2020-04-11 21:55:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0006
2020-04-11 21:55:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0006 running in uber mode : false
2020-04-11 21:55:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 21:55:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0006 failed with state FAILED due to: Application application_1586570645554_0006 failed 2 times due to AM Container for appattempt_1586570645554_0006_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0006Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0006_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 21:55:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 21:56:07 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:56:08 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:56:09 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:56:09 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0007
2020-04-11 21:56:10 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 21:56:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 21:56:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0007
2020-04-11 21:56:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 21:56:11 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 21:56:11 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 21:56:11 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0007
2020-04-11 21:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0007/
2020-04-11 21:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0007
2020-04-11 21:56:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0007 running in uber mode : false
2020-04-11 21:56:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 21:56:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0007 failed with state FAILED due to: Application application_1586570645554_0007 failed 2 times due to AM Container for appattempt_1586570645554_0007_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0007Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0007_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 21:56:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 21:57:15 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:57:17 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:57:17 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:57:17 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0008
2020-04-11 21:57:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0008
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0008
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0008/
2020-04-11 21:57:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0008
2020-04-11 21:57:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0008 running in uber mode : false
2020-04-11 21:57:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 21:57:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0008 failed with state FAILED due to: Application application_1586570645554_0008 failed 2 times due to AM Container for appattempt_1586570645554_0008_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0008Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0008_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 21:57:24 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 21:58:14 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 21:58:15 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 21:58:16 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 21:58:16 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0009
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.jar is deprecated. Instead, use mapreduce.job.jar
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0009
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0009
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0009/
2020-04-11 21:58:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0009
2020-04-11 21:58:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0009 running in uber mode : false
2020-04-11 21:58:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 21:58:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0009 failed with state FAILED due to: Application application_1586570645554_0009 failed 2 times due to AM Container for appattempt_1586570645554_0009_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0009Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0009_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 21:58:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:02:11 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:02:12 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:02:13 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:02:13 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0010
2020-04-11 22:02:14 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:02:14 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:02:14 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.jar is deprecated. Instead, use mapreduce.job.jar
2020-04-11 22:02:14 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0010
2020-04-11 22:02:14 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:02:15 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:02:15 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:02:15 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0010
2020-04-11 22:02:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0010/
2020-04-11 22:02:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0010
2020-04-11 22:02:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0010 running in uber mode : false
2020-04-11 22:02:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:02:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0010 failed with state FAILED due to: Application application_1586570645554_0010 failed 2 times due to AM Container for appattempt_1586570645554_0010_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0010Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0010_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:02:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:04:54 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:04:56 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:04:57 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:04:57 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0011
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.jar is deprecated. Instead, use mapreduce.job.jar
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0011
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0011
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0011/
2020-04-11 22:04:58 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0011
2020-04-11 22:05:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0011 running in uber mode : false
2020-04-11 22:05:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:05:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0011 failed with state FAILED due to: Application application_1586570645554_0011 failed 2 times due to AM Container for appattempt_1586570645554_0011_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0011Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0011_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:05:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:05:42 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:05:43 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:05:44 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:05:44 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0012
2020-04-11 22:05:45 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:05:45 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:05:45 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.jar is deprecated. Instead, use mapreduce.job.jar
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0012
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0012
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0012/
2020-04-11 22:05:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0012
2020-04-11 22:05:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0012 running in uber mode : false
2020-04-11 22:05:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:05:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0012 failed with state FAILED due to: Application application_1586570645554_0012 failed 2 times due to AM Container for appattempt_1586570645554_0012_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0012Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0012_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:05:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:06:08 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:06:09 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:06:10 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:06:10 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0013
2020-04-11 22:06:11 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:06:11 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:06:11 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0013
2020-04-11 22:06:11 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:06:12 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:06:12 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:06:12 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0013
2020-04-11 22:06:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0013/
2020-04-11 22:06:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0013
2020-04-11 22:06:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0013 running in uber mode : false
2020-04-11 22:06:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:06:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0013 failed with state FAILED due to: Application application_1586570645554_0013 failed 2 times due to AM Container for appattempt_1586570645554_0013_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0013Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0013_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:06:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:07:06 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:07:08 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:07:08 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:07:08 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0014
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0014
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0014
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0014/
2020-04-11 22:07:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0014
2020-04-11 22:07:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0014 running in uber mode : false
2020-04-11 22:07:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:07:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0014 failed with state FAILED due to: Application application_1586570645554_0014 failed 2 times due to AM Container for appattempt_1586570645554_0014_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0014Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0014_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:07:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:07:43 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:07:44 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:07:45 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:07:45 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0015
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0015
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0015
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0015/
2020-04-11 22:07:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0015
2020-04-11 22:07:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0015 running in uber mode : false
2020-04-11 22:07:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:07:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0015 failed with state FAILED due to: Application application_1586570645554_0015 failed 2 times due to AM Container for appattempt_1586570645554_0015_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0015Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0015_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:07:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:09:45 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:09:46 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:09:47 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:09:47 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0016
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0016
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0016
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0016/
2020-04-11 22:09:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0016
2020-04-11 22:09:50 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0016 running in uber mode : false
2020-04-11 22:09:50 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:09:50 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0016 failed with state FAILED due to: Application application_1586570645554_0016 failed 2 times due to AM Container for appattempt_1586570645554_0016_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0016Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0016_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:09:50 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-04-11 22:18:34 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:18:36 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:18:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:18:36 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0018
2020-04-11 22:18:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0018
2020-04-11 22:19:07 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-04-11 22:19:08 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-04-11 22:19:09 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-04-11 22:19:09 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1586570645554_0019
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1586570645554_0019
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1586570645554_0019
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1586570645554_0019/
2020-04-11 22:19:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1586570645554_0019
2020-04-11 22:19:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1586570645554_0019 running in uber mode : false
2020-04-11 22:19:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-04-11 22:19:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1586570645554_0019 failed with state FAILED due to: Application application_1586570645554_0019 failed 2 times due to AM Container for appattempt_1586570645554_0019_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1586570645554_0019Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1586570645554_0019_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-04-11 22:19:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 18:45:20 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:45:22 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:45:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:45:23 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0001
2020-07-19 18:45:25 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0001
2020-07-19 18:48:05 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:48:06 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:48:07 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:48:07 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0002
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0002
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0002
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0002/
2020-07-19 18:48:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0002
2020-07-19 18:48:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0002 running in uber mode : false
2020-07-19 18:48:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 18:48:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0002 failed with state FAILED due to: Application application_1595151473703_0002 failed 2 times due to AM Container for appattempt_1595151473703_0002_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0002_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 18:48:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 18:49:14 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:49:16 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-07-19 18:49:16 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2020-07-19 18:49:16 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2020-07-19 18:49:16 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2020-07-19 18:49:17 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:49:17 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:49:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:49:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local835191174_0001
2020-07-19 18:49:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:49:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root835191174/.staging/job_local835191174_0001
2020-07-19 18:53:04 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:53:06 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-07-19 18:53:06 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2020-07-19 18:53:06 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2020-07-19 18:53:06 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2020-07-19 18:53:06 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:53:07 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:53:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:53:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1155810313_0001
2020-07-19 18:53:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:53:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1155810313/.staging/job_local1155810313_0001
2020-07-19 18:56:00 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:56:02 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:56:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:56:03 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0003
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0003
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0003
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0003/
2020-07-19 18:56:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0003
2020-07-19 18:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0003 running in uber mode : false
2020-07-19 18:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 18:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0003 failed with state FAILED due to: Application application_1595151473703_0003 failed 2 times due to AM Container for appattempt_1595151473703_0003_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0003Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0003_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 18:56:11 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 18:57:15 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:57:16 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:57:17 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:57:17 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0004
2020-07-19 18:57:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:57:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:57:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0004
2020-07-19 18:57:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:57:19 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 18:57:19 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 18:57:19 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0004
2020-07-19 18:57:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0004/
2020-07-19 18:57:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0004
2020-07-19 18:57:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0004 running in uber mode : false
2020-07-19 18:57:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 18:57:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0004 failed with state FAILED due to: Application application_1595151473703_0004 failed 2 times due to AM Container for appattempt_1595151473703_0004_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0004Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0004_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 18:57:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 18:58:32 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:58:34 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:58:35 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:58:35 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0005
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0005
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0005
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0005/
2020-07-19 18:58:36 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0005
2020-07-19 18:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0005 running in uber mode : false
2020-07-19 18:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 18:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0005 failed with state FAILED due to: Application application_1595151473703_0005 failed 2 times due to AM Container for appattempt_1595151473703_0005_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0005Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0005_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 18:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 18:59:01 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 18:59:02 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 18:59:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 18:59:03 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0006
2020-07-19 18:59:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 18:59:03 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 18:59:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 18:59:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0006
2020-07-19 18:59:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0006
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0006/
2020-07-19 18:59:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0006
2020-07-19 18:59:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0006 running in uber mode : false
2020-07-19 18:59:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 18:59:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0006 failed with state FAILED due to: Application application_1595151473703_0006 failed 2 times due to AM Container for appattempt_1595151473703_0006_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0006Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0006_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 18:59:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:01:45 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:01:47 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:01:48 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:01:48 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0007
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0007
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0007
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0007/
2020-07-19 19:01:49 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0007
2020-07-19 19:01:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0007 running in uber mode : false
2020-07-19 19:01:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:01:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0007 failed with state FAILED due to: Application application_1595151473703_0007 failed 2 times due to AM Container for appattempt_1595151473703_0007_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0007Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0007_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:01:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:06:26 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:06:28 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:06:29 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:06:29 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0008
2020-07-19 19:06:30 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:06:30 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0008
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0008
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0008/
2020-07-19 19:06:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0008
2020-07-19 19:06:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0008 running in uber mode : false
2020-07-19 19:06:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:06:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0008 failed with state FAILED due to: Application application_1595151473703_0008 failed 2 times due to AM Container for appattempt_1595151473703_0008_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0008Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0008_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:06:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:06:59 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:07:01 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:07:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:07:02 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0009
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0009
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0009
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0009/
2020-07-19 19:07:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0009
2020-07-19 19:07:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0009 running in uber mode : false
2020-07-19 19:07:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:07:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0009 failed with state FAILED due to: Application application_1595151473703_0009 failed 2 times due to AM Container for appattempt_1595151473703_0009_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0009Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0009_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:07:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:07:38 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:07:39 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:07:40 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:07:40 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0010
2020-07-19 19:07:41 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:07:41 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0010
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0010
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0010/
2020-07-19 19:07:42 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0010
2020-07-19 19:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0010 running in uber mode : false
2020-07-19 19:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0010 failed with state FAILED due to: Application application_1595151473703_0010 failed 2 times due to AM Container for appattempt_1595151473703_0010_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0010Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0010_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:08:20 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:08:22 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:08:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:08:23 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0011
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0011
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:08:24 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:08:25 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0011
2020-07-19 19:08:25 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0011/
2020-07-19 19:08:25 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0011
2020-07-19 19:08:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0011 running in uber mode : false
2020-07-19 19:08:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:08:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0011 failed with state FAILED due to: Application application_1595151473703_0011 failed 2 times due to AM Container for appattempt_1595151473703_0011_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0011Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0011_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:08:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:11:03 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:11:05 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:11:06 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0012
2020-07-19 19:11:06 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0012
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0012
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0012/
2020-07-19 19:11:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0012
2020-07-19 19:11:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0012 running in uber mode : false
2020-07-19 19:11:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:11:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0012 failed with state FAILED due to: Application application_1595151473703_0012 failed 2 times due to AM Container for appattempt_1595151473703_0012_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0012Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0012_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:11:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:11:14 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:11:16 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:11:17 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:11:17 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0013
2020-07-19 19:11:17 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:11:17 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:11:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:11:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0013
2020-07-19 19:11:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0013
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0013/
2020-07-19 19:11:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0013
2020-07-19 19:11:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0013 running in uber mode : false
2020-07-19 19:11:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:11:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0013 failed with state FAILED due to: Application application_1595151473703_0013 failed 2 times due to AM Container for appattempt_1595151473703_0013_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0013Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0013_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:11:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:53:26 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:53:28 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:53:29 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:53:29 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/85094/.staging/job_1595151473703_0016
2020-07-19 19:53:29 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:53:29 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:53:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:53:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0016
2020-07-19 19:53:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0016
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0016/
2020-07-19 19:53:30 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0016
2020-07-19 19:53:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0016 running in uber mode : false
2020-07-19 19:53:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:53:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0016 failed with state FAILED due to: Application application_1595151473703_0016 failed 2 times due to AM Container for appattempt_1595151473703_0016_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0016Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0016_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:53:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:54:12 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:54:14 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:54:15 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/85094/.staging/job_1595151473703_0017
2020-07-19 19:54:15 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0017
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0017
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0017/
2020-07-19 19:54:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0017
2020-07-19 19:54:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0017 running in uber mode : false
2020-07-19 19:54:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:54:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0017 failed with state FAILED due to: Application application_1595151473703_0017 failed 2 times due to AM Container for appattempt_1595151473703_0017_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0017Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0017_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:54:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:55:53 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:55:55 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:55:56 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0018
2020-07-19 19:55:56 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0018
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0018
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0018/
2020-07-19 19:55:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0018
2020-07-19 19:56:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0018 running in uber mode : false
2020-07-19 19:56:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:56:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0018 failed with state FAILED due to: Application application_1595151473703_0018 failed 2 times due to AM Container for appattempt_1595151473703_0018_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0018Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0018_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:56:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 19:58:40 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 19:58:41 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 19:58:42 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 19:58:42 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0019
2020-07-19 19:58:42 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 19:58:42 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 19:58:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0019
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0019
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0019/
2020-07-19 19:58:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0019
2020-07-19 19:58:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0019 running in uber mode : false
2020-07-19 19:58:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 19:58:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0019 failed with state FAILED due to: Application application_1595151473703_0019 failed 2 times due to AM Container for appattempt_1595151473703_0019_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0019Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0019_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 19:58:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:16:45 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:16:47 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:16:48 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:16:48 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0022
2020-07-19 20:16:48 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:16:48 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:16:48 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0022
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0022
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0022/
2020-07-19 20:16:49 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0022
2020-07-19 20:16:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0022 running in uber mode : false
2020-07-19 20:16:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:16:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0022 failed with state FAILED due to: Application application_1595151473703_0022 failed 2 times due to AM Container for appattempt_1595151473703_0022_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0022Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0022_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:16:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:16:59 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:17:01 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:17:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0023
2020-07-19 20:17:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0023
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0023
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0023/
2020-07-19 20:17:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0023
2020-07-19 20:17:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0023 running in uber mode : false
2020-07-19 20:17:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:17:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0023 failed with state FAILED due to: Application application_1595151473703_0023 failed 2 times due to AM Container for appattempt_1595151473703_0023_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0023Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0023_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:17:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:20:05 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:20:08 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:20:09 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0024
2020-07-19 20:20:09 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0024
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:20:09 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:20:10 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:20:10 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:20:10 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0024
2020-07-19 20:20:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0024/
2020-07-19 20:20:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0024
2020-07-19 20:20:14 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0024 running in uber mode : false
2020-07-19 20:20:14 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:20:14 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0024 failed with state FAILED due to: Application application_1595151473703_0024 failed 2 times due to AM Container for appattempt_1595151473703_0024_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0024Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0024_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:20:14 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:22:28 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:22:30 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:22:31 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:22:31 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0025
2020-07-19 20:22:31 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:22:31 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:22:32 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:22:32 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0025
2020-07-19 20:22:32 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:22:38 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:22:38 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:22:38 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:22:39 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0025
2020-07-19 20:22:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0025/
2020-07-19 20:22:39 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0025
2020-07-19 20:22:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0025 running in uber mode : false
2020-07-19 20:22:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:22:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0025 failed with state FAILED due to: Application application_1595151473703_0025 failed 2 times due to AM Container for appattempt_1595151473703_0025_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0025Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0025_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:22:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:24:59 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:25:01 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:25:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0026
2020-07-19 20:25:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0026
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0026
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0026/
2020-07-19 20:25:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0026
2020-07-19 20:25:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0026 running in uber mode : false
2020-07-19 20:25:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:25:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0026 failed with state FAILED due to: Application application_1595151473703_0026 failed 2 times due to AM Container for appattempt_1595151473703_0026_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0026Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0026_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:25:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-07-19 20:25:54 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-19 20:25:56 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-07-19 20:25:56 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-07-19 20:25:56 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1595151473703_0027
2020-07-19 20:25:56 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-07-19 20:25:56 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1595151473703_0027
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1595151473703_0027
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1595151473703_0027/
2020-07-19 20:25:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1595151473703_0027
2020-07-19 20:26:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1595151473703_0027 running in uber mode : false
2020-07-19 20:26:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-07-19 20:26:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1595151473703_0027 failed with state FAILED due to: Application application_1595151473703_0027 failed 2 times due to AM Container for appattempt_1595151473703_0027_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1595151473703_0027Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1595151473703_0027_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-07-19 20:26:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-08-02 17:21:49 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-02 17:21:51 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-08-02 17:21:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-02 17:21:52 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1596334640501_0001
2020-08-02 17:21:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2020-08-02 17:21:52 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1596334640501_0001
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-08-02 17:21:53 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-08-02 17:21:54 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1596334640501_0001
2020-08-02 17:21:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1596334640501_0001/
2020-08-02 17:21:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1596334640501_0001
2020-08-02 17:22:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1596334640501_0001 running in uber mode : false
2020-08-02 17:22:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-08-02 17:22:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1596334640501_0001 failed with state FAILED due to: Application application_1596334640501_0001 failed 2 times due to AM Container for appattempt_1596334640501_0001_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1596334640501_0001Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1596334640501_0001_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-08-02 17:22:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-08-26 16:12:29 [ INFO] - Demo -Demo.java(7) -ss存在数据倾斜
2020-08-26 16:12:58 [ INFO] - Demo -Demo.java(7) -ss存在数据倾斜
2020-08-26 16:12:58 [ INFO] - jiang -Demo.java(10) -ss存在数据倾斜
2020-08-26 16:25:20 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-26 16:25:22 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-08-26 16:25:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-26 16:25:23 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1598411731091_0001
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1598411731091_0001
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1598411731091_0001
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1598411731091_0001/
2020-08-26 16:25:25 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1598411731091_0001
2020-08-26 16:25:40 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1598411731091_0001 running in uber mode : false
2020-08-26 16:25:40 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-08-26 16:25:40 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1598411731091_0001 failed with state FAILED due to: Application application_1598411731091_0001 failed 2 times due to AM Container for appattempt_1598411731091_0001_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1598411731091_0001Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1598411731091_0001_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-08-26 16:25:40 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2020-08-26 16:40:42 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-26 16:40:44 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-08-26 16:40:44 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2020-08-26 16:40:45 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2020-08-26 16:40:45 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2020-08-26 16:40:45 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-26 16:40:46 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-26 16:40:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-26 16:40:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local844195490_0001
2020-08-26 16:40:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-26 16:40:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root844195490/.staging/job_local844195490_0001
2020-08-26 16:42:55 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-26 16:42:57 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-08-26 16:42:57 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2020-08-26 16:42:57 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2020-08-26 16:42:57 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2020-08-26 16:42:57 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-26 16:42:58 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-26 16:42:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-26 16:42:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1301811000_0001
2020-08-26 16:42:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-26 16:42:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1301811000/.staging/job_local1301811000_0001
2020-08-26 16:53:27 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-26 16:53:29 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-08-26 16:53:29 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2020-08-26 16:53:29 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2020-08-26 16:53:29 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2020-08-26 16:53:30 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-26 16:53:30 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-26 16:53:30 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-26 16:53:31 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1816136185_0001
2020-08-26 16:53:31 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-26 16:53:31 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1816136185/.staging/job_local1816136185_0001
2020-08-26 16:54:11 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-08-26 16:54:13 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2020-08-26 16:54:14 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2020-08-26 16:54:14 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1598411731091_0002
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1598411731091_0002
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1598411731091_0002
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1598411731091_0002/
2020-08-26 16:54:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1598411731091_0002
2020-08-26 16:54:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1598411731091_0002 running in uber mode : false
2020-08-26 16:54:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2020-08-26 16:54:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1598411731091_0002 failed with state FAILED due to: Application application_1598411731091_0002 failed 2 times due to AM Container for appattempt_1598411731091_0002_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1598411731091_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1598411731091_0002_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2020-08-26 16:54:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 12:19:59 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 12:20:01 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 12:20:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 12:20:03 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0001
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0001
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0001
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0001/
2021-02-25 12:20:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0001
2021-02-25 12:20:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0001 running in uber mode : false
2021-02-25 12:20:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 12:20:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0001 failed with state FAILED due to: Application application_1614226310258_0001 failed 2 times due to AM Container for appattempt_1614226310258_0001_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0001Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0001_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 12:20:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 12:20:57 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 12:20:59 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 12:21:00 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 12:21:00 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0002
2021-02-25 12:21:00 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 12:21:00 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 12:21:00 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0002
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0002
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0002/
2021-02-25 12:21:01 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0002
2021-02-25 12:21:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0002 running in uber mode : false
2021-02-25 12:21:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 12:21:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0002 failed with state FAILED due to: Application application_1614226310258_0002 failed 2 times due to AM Container for appattempt_1614226310258_0002_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0002_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 12:21:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 12:28:29 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 12:28:30 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 12:28:32 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 12:28:32 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0003
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0003
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0003
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0003/
2021-02-25 12:28:33 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0003
2021-02-25 12:28:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0003 running in uber mode : false
2021-02-25 12:28:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 12:28:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0003 failed with state FAILED due to: Application application_1614226310258_0003 failed 2 times due to AM Container for appattempt_1614226310258_0003_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0003Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0003_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 12:28:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 12:32:13 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 12:32:15 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 12:32:15 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 12:32:15 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 12:32:15 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 12:32:16 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 12:32:16 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 12:32:16 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 12:32:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 12:32:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local364986475_0001
2021-02-25 12:32:16 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 12:32:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root364986475/.staging/job_local364986475_0001
2021-02-25 16:30:51 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 16:30:52 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:30:52 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:30:52 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:30:52 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:31:12 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 16:31:13 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:31:13 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:31:13 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:31:13 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:31:32 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 16:31:34 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:31:34 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:31:34 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:31:34 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:31:35 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:31:35 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:31:35 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:31:35 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:31:35 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local845133073_0001
2021-02-25 16:31:35 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:31:35 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/85094845133073/.staging/job_local845133073_0001
2021-02-25 16:32:21 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 16:32:23 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:32:23 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:32:23 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:32:23 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:32:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:32:24 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:32:24 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:32:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:32:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local2006837001_0001
2021-02-25 16:32:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:32:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root2006837001/.staging/job_local2006837001_0001
2021-02-25 16:51:27 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:51:27 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:51:27 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:51:27 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:51:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:51:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:51:27 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local622128761_0001
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local622128761_0001
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:51:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 16:51:28 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local622128761_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-25 16:51:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local622128761_0001 running in uber mode : false
2021-02-25 16:51:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 16:51:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local622128761_0001 failed with state FAILED due to: NA
2021-02-25 16:51:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 16:52:07 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:52:07 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:52:07 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:52:07 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:52:08 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:52:08 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local2035846357_0001
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local2035846357_0001
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local2035846357_0001_m_000000_0
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71a6ad3f
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/word.txt:0+34
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-25 16:52:08 [ WARN] - org.apache.hadoop.mapred.MapTask -MapTask.java(417) -Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.ClassCastException: interface javax.xml.soap.Text
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-25 16:52:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-25 16:52:08 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local2035846357_0001
java.lang.Exception: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.ClassCastException: interface javax.xml.soap.Text
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.ClassCastException: interface javax.xml.soap.Text
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:423)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: interface javax.xml.soap.Text
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	... 10 more
2021-02-25 16:52:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local2035846357_0001 running in uber mode : false
2021-02-25 16:52:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 16:52:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local2035846357_0001 failed with state FAILED due to: NA
2021-02-25 16:52:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 16:52:28 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:52:28 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:52:28 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:52:28 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:53:07 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:53:07 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:53:07 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:53:07 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:53:08 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:53:08 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1188803639_0001
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1188803639_0001
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:53:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 16:53:08 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local1188803639_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-25 16:53:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1188803639_0001 running in uber mode : false
2021-02-25 16:53:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 16:53:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local1188803639_0001 failed with state FAILED due to: NA
2021-02-25 16:53:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 16:55:51 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:55:51 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:55:51 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:55:51 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:55:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:55:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1131617127_0001
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1131617127_0001
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:55:52 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 16:55:52 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local1131617127_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/out5/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-25 16:55:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1131617127_0001 running in uber mode : false
2021-02-25 16:55:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 16:55:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local1131617127_0001 failed with state FAILED due to: NA
2021-02-25 16:55:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 16:56:55 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 16:56:55 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 16:56:55 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 16:56:55 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 16:56:55 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 16:56:55 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 16:56:55 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 16:56:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1348697238_0001
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1348697238_0001
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1348697238_0001_m_000000_0
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@508c000d
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/word.txt:0+34
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-25 16:56:56 [ WARN] - org.apache.hadoop.mapred.MapTask -MapTask.java(417) -Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.ClassCastException: interface javax.xml.soap.Text
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-25 16:56:56 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-25 16:56:56 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local1348697238_0001
java.lang.Exception: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.ClassCastException: interface javax.xml.soap.Text
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.ClassCastException: interface javax.xml.soap.Text
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:423)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassCastException: interface javax.xml.soap.Text
	at java.lang.Class.asSubclass(Class.java:3404)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	... 10 more
2021-02-25 16:56:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1348697238_0001 running in uber mode : false
2021-02-25 16:56:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 16:56:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local1348697238_0001 failed with state FAILED due to: NA
2021-02-25 16:56:57 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:00:56 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 17:00:56 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 17:00:56 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 17:00:56 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 17:01:17 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-25 17:01:17 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-25 17:01:17 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-25 17:01:17 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-25 17:01:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:01:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local474218686_0001
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local474218686_0001
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@357ddcf6
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/word.txt:0+34
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-25 17:01:18 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 69; bufvoid = 104857600
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local474218686_0001_m_000000_0 is done. And is in the process of committing
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local474218686_0001_m_000000_0' done.
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local474218686_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=147
		FILE: Number of bytes written=496777
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=3
		Map output records=9
		Map output bytes=69
		Map output materialized bytes=101
		Input split bytes=91
		Combine input records=9
		Combine output records=8
		Spilled Records=8
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	File Input Format Counters 
		Bytes Read=34
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local474218686_0001_r_000000_0
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@9360327
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2564bc1d
2021-02-25 17:01:19 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local474218686_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local474218686_0001_m_000000_0 decomp: 10 len: 14 to MEMORY
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 10 bytes from map-output for attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 10, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 10 bytes to disk to satisfy reduce memory limit
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 14 bytes from disk
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local474218686_0001 running in uber mode : false
2021-02-25 17:01:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local474218686_0001_r_000000_0 is done. And is in the process of committing
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local474218686_0001_r_000000_0 is allowed to commit now
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local474218686_0001_r_000000_0' to hdfs://node1:9000/out5
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local474218686_0001_r_000000_0' done.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local474218686_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=366
		FILE: Number of bytes written=496791
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34
		HDFS: Number of bytes written=4
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=14
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=4
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local474218686_0001_r_000000_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local474218686_0001_r_000001_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1710f4bd
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@79825e68
2021-02-25 17:01:20 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local474218686_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local474218686_0001_m_000000_0 decomp: 11 len: 15 to MEMORY
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 11 bytes from map-output for attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 11 bytes to disk to satisfy reduce memory limit
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 15 bytes from disk
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local474218686_0001_r_000001_0 is done. And is in the process of committing
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local474218686_0001_r_000001_0 is allowed to commit now
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local474218686_0001_r_000001_0' to hdfs://node1:9000/out5
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local474218686_0001_r_000001_0' done.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local474218686_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=572
		FILE: Number of bytes written=496806
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34
		HDFS: Number of bytes written=9
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=15
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=5
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local474218686_0001_r_000001_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local474218686_0001_r_000002_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@58da472d
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@778dd0c9
2021-02-25 17:01:20 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local474218686_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#3 about to shuffle output of map attempt_local474218686_0001_m_000000_0 decomp: 31 len: 35 to MEMORY
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 31 bytes from map-output for attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 31, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 25 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 31 bytes to disk to satisfy reduce memory limit
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 35 bytes from disk
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 25 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local474218686_0001_r_000002_0 is done. And is in the process of committing
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local474218686_0001_r_000002_0 is allowed to commit now
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local474218686_0001_r_000002_0' to hdfs://node1:9000/out5
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local474218686_0001_r_000002_0' done.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local474218686_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=783
		FILE: Number of bytes written=496841
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34
		HDFS: Number of bytes written=26
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=35
		Reduce input records=3
		Reduce output records=3
		Spilled Records=3
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local474218686_0001_r_000002_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local474218686_0001_r_000003_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@77ed9dbc
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@277c4829
2021-02-25 17:01:20 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local474218686_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#4 about to shuffle output of map attempt_local474218686_0001_m_000000_0 decomp: 33 len: 37 to MEMORY
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 33 bytes from map-output for attempt_local474218686_0001_m_000000_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 33, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->33
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 27 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 33 bytes to disk to satisfy reduce memory limit
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 37 bytes from disk
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 27 bytes
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local474218686_0001_r_000003_0 is done. And is in the process of committing
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local474218686_0001_r_000003_0 is allowed to commit now
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local474218686_0001_r_000003_0' to hdfs://node1:9000/out5
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local474218686_0001_r_000003_0' done.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local474218686_0001_r_000003_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=961
		FILE: Number of bytes written=496878
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=34
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=9
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=37
		Reduce input records=3
		Reduce output records=3
		Spilled Records=3
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=19
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local474218686_0001_r_000003_0
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local474218686_0001 completed successfully
2021-02-25 17:01:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=2829
		FILE: Number of bytes written=2484093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=170
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=75
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=25
	Map-Reduce Framework
		Map input records=3
		Map output records=9
		Map output bytes=69
		Map output materialized bytes=101
		Input split bytes=91
		Combine input records=9
		Combine output records=8
		Reduce input groups=8
		Reduce shuffle bytes=101
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1578106880
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=34
	File Output Format Counters 
		Bytes Written=45
2021-02-25 17:26:02 [ WARN] - org.apache.hadoop.util.Shell -Shell.java(694) -Did not find winutils.exe: {}
java.io.FileNotFoundException: java.io.FileNotFoundException: Hadoop home directory D:\winutil does not exist -see https://wiki.apache.org/hadoop/WindowsProblems
	at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:549)
	at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:570)
	at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:593)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:690)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1664)
	at org.apache.hadoop.security.SecurityUtil.setConfigurationInternal(SecurityUtil.java:102)
	at org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:86)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:315)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:303)
	at org.apache.hadoop.security.UserGroupInformation.doSubjectLogin(UserGroupInformation.java:1827)
	at org.apache.hadoop.security.UserGroupInformation.createLoginUser(UserGroupInformation.java:709)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:659)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:570)
	at org.apache.hadoop.mapreduce.task.JobContextImpl.<init>(JobContextImpl.java:72)
	at org.apache.hadoop.mapreduce.Job.<init>(Job.java:150)
	at org.apache.hadoop.mapreduce.Job.getInstance(Job.java:193)
	at org.apache.hadoop.mapreduce.Job.getInstance(Job.java:212)
	at WordCount.WordMain.main(WordMain.java:32)
Caused by: java.io.FileNotFoundException: Hadoop home directory D:\winutil does not exist
	at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:492)
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:440)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:517)
	... 15 more
2021-02-25 17:26:02 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-25 17:26:04 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:26:05 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:26:05 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0004
2021-02-25 17:26:06 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:26:06 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0004
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0004
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0004/
2021-02-25 17:26:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0004
2021-02-25 17:26:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0004 running in uber mode : false
2021-02-25 17:26:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:26:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0004 failed with state FAILED due to: Application application_1614226310258_0004 failed 2 times due to AM Container for appattempt_1614226310258_0004_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0004Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0004_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:26:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:27:48 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:27:49 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:27:49 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0005
2021-02-25 17:27:50 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:27:50 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0005
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0005
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0005/
2021-02-25 17:27:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0005
2021-02-25 17:27:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0005 running in uber mode : false
2021-02-25 17:27:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:27:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0005 failed with state FAILED due to: Application application_1614226310258_0005 failed 2 times due to AM Container for appattempt_1614226310258_0005_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0005Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0005_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:27:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:31:53 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:31:54 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:31:54 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0006
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0006
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0006
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0006/
2021-02-25 17:31:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0006
2021-02-25 17:32:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0006 running in uber mode : false
2021-02-25 17:32:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:32:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0006 failed with state FAILED due to: Application application_1614226310258_0006 failed 2 times due to AM Container for appattempt_1614226310258_0006_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0006Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0006_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:32:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:37:54 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:37:55 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:37:55 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0007
2021-02-25 17:37:58 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:37:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:37:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0007
2021-02-25 17:37:58 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:37:59 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:37:59 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:37:59 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0007
2021-02-25 17:37:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0007/
2021-02-25 17:37:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0007
2021-02-25 17:38:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0007 running in uber mode : false
2021-02-25 17:38:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:38:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0007 failed with state FAILED due to: Application application_1614226310258_0007 failed 2 times due to AM Container for appattempt_1614226310258_0007_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0007Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0007_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:38:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:46:30 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:46:31 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:46:31 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0008
2021-02-25 17:46:33 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:46:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:46:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0008
2021-02-25 17:46:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:46:34 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:46:34 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:46:34 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0008
2021-02-25 17:46:34 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0008/
2021-02-25 17:46:34 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0008
2021-02-25 17:46:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0008 running in uber mode : false
2021-02-25 17:46:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:46:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0008 failed with state FAILED due to: Application application_1614226310258_0008 failed 2 times due to AM Container for appattempt_1614226310258_0008_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0008Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0008_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:46:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:48:44 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:48:45 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:48:45 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0009
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0009
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0009
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0009/
2021-02-25 17:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0009
2021-02-25 17:48:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0009 running in uber mode : false
2021-02-25 17:48:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:48:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0009 failed with state FAILED due to: Application application_1614226310258_0009 failed 2 times due to AM Container for appattempt_1614226310258_0009_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0009Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0009_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:48:51 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 17:49:24 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 17:49:25 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 17:49:25 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0010
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0010
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0010
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0010/
2021-02-25 17:49:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0010
2021-02-25 17:49:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0010 running in uber mode : false
2021-02-25 17:49:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 17:49:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0010 failed with state FAILED due to: Application application_1614226310258_0010 failed 2 times due to AM Container for appattempt_1614226310258_0010_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0010Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0010_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 17:49:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 18:01:15 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 18:01:16 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 18:01:16 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0011
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0011
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 18:01:17 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0011
2021-02-25 18:01:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0011/
2021-02-25 18:01:18 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0011
2021-02-25 18:01:23 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0011 running in uber mode : false
2021-02-25 18:01:23 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 18:01:23 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0011 failed with state FAILED due to: Application application_1614226310258_0011 failed 2 times due to AM Container for appattempt_1614226310258_0011_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0011Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0011_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 18:01:23 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 18:28:10 [ INFO] - Demo -Demo.java(7) -ss存在数据倾斜
2021-02-25 18:28:10 [ INFO] - jiang -Demo.java(10) -ss存在数据倾斜
2021-02-25 18:28:23 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 18:28:24 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 18:28:24 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0012
2021-02-25 18:28:25 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 18:28:25 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0012
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0012
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0012/
2021-02-25 18:28:26 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0012
2021-02-25 18:28:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0012 running in uber mode : false
2021-02-25 18:28:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 18:28:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0012 failed with state FAILED due to: Application application_1614226310258_0012 failed 2 times due to AM Container for appattempt_1614226310258_0012_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0012Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0012_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 18:28:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-25 18:28:51 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-25 18:28:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-25 18:28:52 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614226310258_0013
2021-02-25 18:28:53 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614226310258_0013
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614226310258_0013
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614226310258_0013/
2021-02-25 18:28:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614226310258_0013
2021-02-25 18:28:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614226310258_0013 running in uber mode : false
2021-02-25 18:28:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-25 18:28:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614226310258_0013 failed with state FAILED due to: Application application_1614226310258_0013 failed 2 times due to AM Container for appattempt_1614226310258_0013_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614226310258_0013Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614226310258_0013_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-25 18:28:59 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 11:04:33 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:04:35 [ INFO] - org.apache.hadoop.yarn.client.RMProxy -RMProxy.java(133) -Connecting to ResourceManager at node1/192.168.200.11:18040
2021-02-26 11:04:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:04:36 [ INFO] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(883) -Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1614297449984_0002
2021-02-26 11:04:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:04:36 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_1614297449984_0002
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapred.YARNRunner -YARNRunner.java(426) -Job jar is not present. Not adding any jar to the list of resources.
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.conf.Configuration -Configuration.java(2752) -resource-types.xml not found
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.yarn.util.resource.ResourceUtils -ResourceUtils.java(418) -Unable to find 'resource-types.xml'.
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.yarn.client.api.impl.YarnClientImpl -YarnClientImpl.java(324) -Submitted application application_1614297449984_0002
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://node1:18088/proxy/application_1614297449984_0002/
2021-02-26 11:04:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_1614297449984_0002
2021-02-26 11:04:41 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_1614297449984_0002 running in uber mode : false
2021-02-26 11:04:41 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 11:04:41 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_1614297449984_0002 failed with state FAILED due to: Application application_1614297449984_0002 failed 2 times due to AM Container for appattempt_1614297449984_0002_000002 exited with  exitCode: 1
For more detailed output, check application tracking page:http://node1:18088/cluster/app/application_1614297449984_0002Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1614297449984_0002_02_000001
Exit code: 1
Exception message: /bin/bash: line 0: fg: no job control

Stack trace: ExitCodeException exitCode=1: /bin/bash: line 0: fg: no job control

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


Container exited with a non-zero exit code 1
Failing this attempt. Failing the application.
2021-02-26 11:04:41 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 11:05:21 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:05:22 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:05:22 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:05:22 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:05:22 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:05:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:05:23 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:05:23 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:05:23 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:05:23 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1106182539_0001
2021-02-26 11:05:23 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:05:24 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1106182539/.staging/job_local1106182539_0001
2021-02-26 11:05:49 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:05:51 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:05:51 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:05:51 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:05:51 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:05:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:05:52 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:05:52 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:05:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:05:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1055679350_0001
2021-02-26 11:05:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:05:52 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1055679350/.staging/job_local1055679350_0001
2021-02-26 11:07:16 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:07:17 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:07:17 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:07:17 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:07:17 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:07:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:07:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:07:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:07:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:07:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1337914953_0001
2021-02-26 11:07:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:07:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1337914953/.staging/job_local1337914953_0001
2021-02-26 11:10:26 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:10:28 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:10:28 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:10:28 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:10:28 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:10:28 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:10:28 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:10:28 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:10:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:10:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local697805128_0001
2021-02-26 11:10:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:10:29 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root697805128/.staging/job_local697805128_0001
2021-02-26 11:12:09 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:12:11 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:12:11 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:12:11 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:12:11 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:12:11 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:12:11 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:12:11 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:12:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:12:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1349824712_0001
2021-02-26 11:12:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:12:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root1349824712/.staging/job_local1349824712_0001
2021-02-26 11:15:00 [ WARN] - org.apache.hadoop.util.NativeCodeLoader -NativeCodeLoader.java(60) -Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-02-26 11:15:02 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 11:15:02 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 11:15:02 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 11:15:02 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 11:15:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 11:15:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 11:15:03 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 11:15:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 11:15:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local810511636_0001
2021-02-26 11:15:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 11:15:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(260) -Cleaning up the staging area file:/tmp/hadoop/mapred/staging/root810511636/.staging/job_local810511636_0001
2021-02-26 12:57:27 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 12:57:27 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 12:57:27 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 12:57:27 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 12:57:28 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 12:57:28 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local870115445_0001
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local870115445_0001
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local870115445_0001_m_000000_0
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a2801ed
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/word.txt:0+34
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 12:57:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 12:57:29 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local870115445_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NullPointerException
	at WordCount.CustomPartitioner.getPartition(CustomPartitioner.java:23)
	at WordCount.CustomPartitioner.getPartition(CustomPartitioner.java:9)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:728)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at WordCount.WordMap.map(WordMap.java:19)
	at WordCount.WordMap.map(WordMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local870115445_0001 running in uber mode : false
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local870115445_0001 failed with state FAILED due to: NA
2021-02-26 12:57:29 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 12:58:12 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 12:58:12 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 12:58:12 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 12:58:12 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:09:11 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:09:11 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:09:11 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:09:11 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:09:12 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:09:12 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1007987544_0001
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1007987544_0001
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1007987544_0001_m_000000_0
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3dce9c93
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/word.txt:0+34
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:09:12 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:09:13 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local1007987544_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.NullPointerException
	at WordCount.CustomPartitioner.getPartition(CustomPartitioner.java:23)
	at WordCount.CustomPartitioner.getPartition(CustomPartitioner.java:9)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:728)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at WordCount.WordMap.map(WordMap.java:19)
	at WordCount.WordMap.map(WordMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1007987544_0001 running in uber mode : false
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local1007987544_0001 failed with state FAILED due to: NA
2021-02-26 13:09:13 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 13:10:35 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:10:36 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:10:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:10:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local717719816_0001
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local717719816_0001
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f33084f
2021-02-26 13:10:36 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/customPartition.txt:0+71
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 131; bufvoid = 104857600
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local717719816_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local717719816_0001_m_000000_0' done.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local717719816_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=158
		FILE: Number of bytes written=497220
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=71
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=4
		Map output records=15
		Map output bytes=131
		Map output materialized bytes=68
		Input split bytes=102
		Combine input records=15
		Combine output records=4
		Spilled Records=4
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	File Input Format Counters 
		Bytes Read=71
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local717719816_0001_r_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7306169f
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a83c54e
2021-02-26 13:10:37 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local717719816_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local717719816_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 13 bytes from map-output for attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 17 bytes from disk
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local717719816_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local717719816_0001_r_000000_0 is allowed to commit now
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local717719816_0001_r_000000_0' to hdfs://node1:9000/out659
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local717719816_0001_r_000000_0' done.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local717719816_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=347
		FILE: Number of bytes written=497237
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=71
		HDFS: Number of bytes written=7
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=17
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=7
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local717719816_0001_r_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local717719816_0001_r_000001_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b9a1130
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22046307
2021-02-26 13:10:37 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local717719816_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local717719816_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 13 bytes from map-output for attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 17 bytes from disk
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local717719816_0001_r_000001_0 is done. And is in the process of committing
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local717719816_0001_r_000001_0 is allowed to commit now
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local717719816_0001 running in uber mode : false
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 25%
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local717719816_0001_r_000001_0' to hdfs://node1:9000/out659
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local717719816_0001_r_000001_0' done.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local717719816_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=519
		FILE: Number of bytes written=497254
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=71
		HDFS: Number of bytes written=14
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=17
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=7
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local717719816_0001_r_000001_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local717719816_0001_r_000002_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74596e98
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@760e906f
2021-02-26 13:10:37 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local717719816_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#3 about to shuffle output of map attempt_local717719816_0001_m_000000_0 decomp: 14 len: 18 to MEMORY
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 14 bytes from map-output for attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 14 bytes to disk to satisfy reduce memory limit
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 18 bytes from disk
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local717719816_0001_r_000002_0 is done. And is in the process of committing
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local717719816_0001_r_000002_0 is allowed to commit now
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local717719816_0001_r_000002_0' to hdfs://node1:9000/out659
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local717719816_0001_r_000002_0' done.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local717719816_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=675
		FILE: Number of bytes written=497272
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=71
		HDFS: Number of bytes written=22
		HDFS: Number of read operations=20
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=18
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=8
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local717719816_0001_r_000002_0
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local717719816_0001_r_000003_0
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@59a1fefb
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@89fa916
2021-02-26 13:10:38 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local717719816_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#4 about to shuffle output of map attempt_local717719816_0001_m_000000_0 decomp: 12 len: 16 to MEMORY
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 12 bytes from map-output for attempt_local717719816_0001_m_000000_0
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 12 bytes to disk to satisfy reduce memory limit
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 16 bytes from disk
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local717719816_0001_r_000003_0 is done. And is in the process of committing
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local717719816_0001_r_000003_0 is allowed to commit now
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local717719816_0001_r_000003_0' to hdfs://node1:9000/out659
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local717719816_0001_r_000003_0' done.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local717719816_0001_r_000003_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=811
		FILE: Number of bytes written=497288
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=71
		HDFS: Number of bytes written=28
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=9
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=16
		Reduce input records=1
		Reduce output records=1
		Spilled Records=1
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=6
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local717719816_0001_r_000003_0
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local717719816_0001 completed successfully
2021-02-26 13:10:38 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=2510
		FILE: Number of bytes written=2486271
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=355
		HDFS: Number of bytes written=71
		HDFS: Number of read operations=75
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=25
	Map-Reduce Framework
		Map input records=4
		Map output records=15
		Map output bytes=131
		Map output materialized bytes=68
		Input split bytes=102
		Combine input records=15
		Combine output records=4
		Reduce input groups=4
		Reduce shuffle bytes=68
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1580728320
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=71
	File Output Format Counters 
		Bytes Written=28
2021-02-26 13:44:54 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:44:54 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:44:54 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:44:54 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:44:55 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:44:55 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local837002172_0001
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local837002172_0001
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:44:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:44:55 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local837002172_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/ou/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/ou/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-26 13:44:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local837002172_0001 running in uber mode : false
2021-02-26 13:44:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 13:44:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local837002172_0001 failed with state FAILED due to: NA
2021-02-26 13:44:56 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 13:45:18 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:45:18 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:45:18 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:45:18 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:45:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:45:18 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:45:18 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:45:18 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local667982075_0001
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local667982075_0001
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local667982075_0001_m_000000_0
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@773dfe59
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/secondarySort.txt:0+103
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:45:19 [ WARN] - org.apache.hadoop.mapred.MapTask -MapTask.java(417) -Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.io.WritableComparator.newKey(WritableComparator.java:144)
	at org.apache.hadoop.io.WritableComparator.<init>(WritableComparator.java:130)
	at org.apache.hadoop.io.WritableComparator.get(WritableComparator.java:65)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 16 more
2021-02-26 13:45:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:45:19 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local667982075_0001
java.lang.Exception: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:423)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.io.WritableComparator.newKey(WritableComparator.java:144)
	at org.apache.hadoop.io.WritableComparator.<init>(WritableComparator.java:130)
	at org.apache.hadoop.io.WritableComparator.get(WritableComparator.java:65)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	... 10 more
Caused by: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 16 more
2021-02-26 13:45:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local667982075_0001 running in uber mode : false
2021-02-26 13:45:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 13:45:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local667982075_0001 failed with state FAILED due to: NA
2021-02-26 13:45:20 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 13:48:44 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:48:44 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:48:44 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:48:44 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:48:44 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:48:44 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:48:44 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local498838744_0001
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local498838744_0001
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local498838744_0001_m_000000_0
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2aba39d9
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/secondarySort.txt:0+103
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 106; bufvoid = 104857600
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local498838744_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local498838744_0001_m_000000_0' done.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local498838744_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=156
		FILE: Number of bytes written=495873
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=106
		Map output materialized bytes=132
		Input split bytes=100
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=317718528
	File Input Format Counters 
		Bytes Read=103
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local498838744_0001_m_000000_0
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local498838744_0001_r_000000_0
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71ab06d1
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6dea4154
2021-02-26 13:48:45 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local498838744_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local498838744_0001_m_000000_0 decomp: 68 len: 72 to MEMORY
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 68 bytes from map-output for attempt_local498838744_0001_m_000000_0
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 68, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->68
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 51 bytes
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 68 bytes to disk to satisfy reduce memory limit
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 72 bytes from disk
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 51 bytes
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:45 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local498838744_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local498838744_0001_r_000000_0 is allowed to commit now
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local498838744_0001_r_000000_0' to hdfs://node1:9000/ou
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local498838744_0001_r_000000_0' done.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local498838744_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=416
		FILE: Number of bytes written=495945
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=120
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=72
		Reduce input records=4
		Reduce output records=4
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=317718528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=120
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local498838744_0001_r_000000_0
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local498838744_0001_r_000001_0
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@31583e6b
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@285874df
2021-02-26 13:48:46 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local498838744_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local498838744_0001_m_000000_0 decomp: 56 len: 60 to MEMORY
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 56 bytes from map-output for attempt_local498838744_0001_m_000000_0
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 56, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->56
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 36 bytes
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 56 bytes to disk to satisfy reduce memory limit
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 60 bytes from disk
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 36 bytes
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local498838744_0001_r_000001_0 is done. And is in the process of committing
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local498838744_0001_r_000001_0 is allowed to commit now
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local498838744_0001_r_000001_0' to hdfs://node1:9000/ou
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local498838744_0001_r_000001_0' done.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local498838744_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=592
		FILE: Number of bytes written=496005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=210
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=60
		Reduce input records=3
		Reduce output records=3
		Spilled Records=3
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=317718528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=90
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local498838744_0001_r_000001_0
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local498838744_0001 running in uber mode : false
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local498838744_0001 completed successfully
2021-02-26 13:48:46 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=1164
		FILE: Number of bytes written=1487823
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=309
		HDFS: Number of bytes written=330
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=12
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=106
		Map output materialized bytes=132
		Input split bytes=100
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=132
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=953155584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=103
	File Output Format Counters 
		Bytes Written=210
2021-02-26 13:50:03 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:50:03 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:50:03 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:50:03 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:50:04 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:50:04 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1755417811_0001
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1755417811_0001
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1755417811_0001_m_000000_0
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2cd44e9a
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/secondarySort.txt:0+103
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:50:04 [ WARN] - org.apache.hadoop.mapred.MapTask -MapTask.java(417) -Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer
java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.io.WritableComparator.newKey(WritableComparator.java:144)
	at org.apache.hadoop.io.WritableComparator.<init>(WritableComparator.java:130)
	at org.apache.hadoop.io.WritableComparator.get(WritableComparator.java:65)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 16 more
2021-02-26 13:50:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:50:04 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local1755417811_0001
java.lang.Exception: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.IOException: Initialization of all the collectors failed. Error in last collector was:java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:423)
	at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:82)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<init>(MapTask.java:710)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:782)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.io.WritableComparator.newKey(WritableComparator.java:144)
	at org.apache.hadoop.io.WritableComparator.<init>(WritableComparator.java:130)
	at org.apache.hadoop.io.WritableComparator.get(WritableComparator.java:65)
	at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:885)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1018)
	at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:408)
	... 10 more
Caused by: java.lang.NoSuchMethodException: SecondarySort.Person.<init>()
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getDeclaredConstructor(Class.java:2178)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 16 more
2021-02-26 13:50:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1755417811_0001 running in uber mode : false
2021-02-26 13:50:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 13:50:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local1755417811_0001 failed with state FAILED due to: NA
2021-02-26 13:50:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 13:51:41 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 13:51:41 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 13:51:42 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 13:51:42 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local169118668_0001
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local169118668_0001
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local169118668_0001_m_000000_0
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4006a32c
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/secondarySort.txt:0+103
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 13:51:42 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 106; bufvoid = 104857600
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local169118668_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local169118668_0001_m_000000_0' done.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local169118668_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=156
		FILE: Number of bytes written=495873
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=106
		Map output materialized bytes=132
		Input split bytes=100
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	File Input Format Counters 
		Bytes Read=103
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local169118668_0001_m_000000_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local169118668_0001_r_000000_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50ea0d38
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38d473e2
2021-02-26 13:51:43 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local169118668_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local169118668_0001_m_000000_0 decomp: 71 len: 75 to MEMORY
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 71 bytes from map-output for attempt_local169118668_0001_m_000000_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 71, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->71
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 51 bytes
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 71 bytes to disk to satisfy reduce memory limit
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 75 bytes from disk
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 51 bytes
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local169118668_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local169118668_0001_r_000000_0 is allowed to commit now
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local169118668_0001_r_000000_0' to hdfs://node1:9000/ou
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local169118668_0001_r_000000_0' done.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local169118668_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=419
		FILE: Number of bytes written=495948
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=172
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=75
		Reduce input records=4
		Reduce output records=4
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=172
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local169118668_0001_r_000000_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local169118668_0001_r_000001_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41e0ee9
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32015036
2021-02-26 13:51:43 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local169118668_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local169118668_0001_m_000000_0 decomp: 53 len: 57 to MEMORY
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 53 bytes from map-output for attempt_local169118668_0001_m_000000_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 53, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->53
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 36 bytes
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 53 bytes to disk to satisfy reduce memory limit
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 57 bytes from disk
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 36 bytes
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local169118668_0001 running in uber mode : false
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 50%
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local169118668_0001_r_000001_0 is done. And is in the process of committing
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local169118668_0001_r_000001_0 is allowed to commit now
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local169118668_0001_r_000001_0' to hdfs://node1:9000/ou
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local169118668_0001_r_000001_0' done.
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local169118668_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=589
		FILE: Number of bytes written=496005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=103
		HDFS: Number of bytes written=299
		HDFS: Number of read operations=16
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=57
		Reduce input records=3
		Reduce output records=3
		Spilled Records=3
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=127
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local169118668_0001_r_000001_0
2021-02-26 13:51:43 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 13:51:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 13:51:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local169118668_0001 completed successfully
2021-02-26 13:51:44 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=1164
		FILE: Number of bytes written=1487826
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=309
		HDFS: Number of bytes written=471
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=12
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=106
		Map output materialized bytes=132
		Input split bytes=100
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=132
		Reduce input records=7
		Reduce output records=7
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=948436992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=103
	File Output Format Counters 
		Bytes Written=299
2021-02-26 15:55:04 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 15:55:04 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 15:55:04 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 15:55:04 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 15:56:46 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 15:56:46 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 15:56:46 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 15:56:46 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 15:56:47 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 15:56:47 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local519448144_0001
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local519448144_0001
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 15:56:47 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 15:56:47 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local519448144_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/GlobalSort_out/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/GlobalSort_out/_temporary/0":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-26 15:56:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local519448144_0001 running in uber mode : false
2021-02-26 15:56:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 15:56:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local519448144_0001 failed with state FAILED due to: NA
2021-02-26 15:56:48 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 15:57:06 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 15:57:06 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 15:57:06 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 15:57:06 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 15:57:07 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 15:57:07 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local2088322556_0001
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local2088322556_0001
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local2088322556_0001_m_000000_0
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@43502a7f
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 15:57:07 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 920864; bufvoid = 104857600
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188144(104752576); length = 26253/6553600
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local2088322556_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local2088322556_0001_m_000000_0' done.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local2088322556_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=157
		FILE: Number of bytes written=1439404
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888190
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940551
		Input split bytes=98
		Combine input records=0
		Spilled Records=6564
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	File Input Format Counters 
		Bytes Read=888190
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local2088322556_0001_m_000000_0
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local2088322556_0001_r_000000_0
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a6952f6
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c8407b5
2021-02-26 15:57:08 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local2088322556_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local2088322556_0001_m_000000_0 decomp: 940547 len: 940551 to MEMORY
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 940547 bytes from map-output for attempt_local2088322556_0001_m_000000_0
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 940547, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->940547
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 940540 bytes
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 940547 bytes to disk to satisfy reduce memory limit
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 940551 bytes from disk
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 940540 bytes
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 15:57:08 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local2088322556_0001 running in uber mode : false
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local2088322556_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local2088322556_0001_r_000000_0 is allowed to commit now
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local2088322556_0001_r_000000_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local2088322556_0001_r_000000_0' done.
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local2088322556_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1881291
		FILE: Number of bytes written=2379955
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888190
		HDFS: Number of bytes written=80293
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=111
		Reduce shuffle bytes=940551
		Reduce input records=6564
		Reduce output records=6564
		Spilled Records=6564
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=316145664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=80293
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local2088322556_0001_r_000000_0
2021-02-26 15:57:08 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 15:57:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 15:57:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local2088322556_0001 completed successfully
2021-02-26 15:57:09 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=1881448
		FILE: Number of bytes written=3819359
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1776380
		HDFS: Number of bytes written=80293
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940551
		Input split bytes=98
		Combine input records=0
		Combine output records=0
		Reduce input groups=111
		Reduce shuffle bytes=940551
		Reduce input records=6564
		Reduce output records=6564
		Spilled Records=13128
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=80293
2021-02-26 15:59:45 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 15:59:45 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 15:59:45 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 15:59:45 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:00:36 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:00:36 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:00:36 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:00:36 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:00:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 16:00:36 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 16:00:36 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 16:00:36 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1633709068_0001
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1633709068_0001
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1633709068_0001_m_000000_0
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2ca00324
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 16:00:37 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 16:01:22 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1633709068_0001 running in uber mode : false
2021-02-26 16:03:00 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map > map
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.hdfs.client.impl.BlockReaderRemote -BlockReaderRemote.java(329) -Could not send read status (CHECKSUM_OK) to datanode /192.168.200.13:50010: 你的主机中的软件中止了一个已建立的连接。
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map > map
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 920864; bufvoid = 104857600
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188144(104752576); length = 26253/6553600
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1633709068_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1633709068_0001_m_000000_0' done.
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1633709068_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=157
		FILE: Number of bytes written=1439404
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888190
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940551
		Input split bytes=98
		Combine input records=0
		Spilled Records=6564
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=256901120
	File Input Format Counters 
		Bytes Read=888190
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1633709068_0001_m_000000_0
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local1633709068_0001_r_000000_0
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11c4fba5
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c96adfe
2021-02-26 16:03:09 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 16:03:09 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local1633709068_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local1633709068_0001_m_000000_0 decomp: 940547 len: 940551 to MEMORY
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 940547 bytes from map-output for attempt_local1633709068_0001_m_000000_0
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 940547, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->940547
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 940540 bytes
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 1 segments, 940547 bytes to disk to satisfy reduce memory limit
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 940551 bytes from disk
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 940540 bytes
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 16:03:10 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1633709068_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -1 / 1 copied.
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1633709068_0001_r_000000_0 is allowed to commit now
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1633709068_0001_r_000000_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1633709068_0001_r_000000_0' done.
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1633709068_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1881291
		FILE: Number of bytes written=2379955
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888190
		HDFS: Number of bytes written=80293
		HDFS: Number of read operations=10
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=111
		Reduce shuffle bytes=940551
		Reduce input records=6564
		Reduce output records=6564
		Spilled Records=6564
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=251658240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=80293
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local1633709068_0001_r_000000_0
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local1633709068_0001 completed successfully
2021-02-26 16:03:10 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=1881448
		FILE: Number of bytes written=3819359
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1776380
		HDFS: Number of bytes written=80293
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940551
		Input split bytes=98
		Combine input records=0
		Combine output records=0
		Reduce input groups=111
		Reduce shuffle bytes=940551
		Reduce input records=6564
		Reduce output records=6564
		Spilled Records=13128
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=508559360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=80293
2021-02-26 16:03:37 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:03:37 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:03:37 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:03:37 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:04:18 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:04:18 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:04:19 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 16:04:19 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local722503863_0001
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local722503863_0001
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local722503863_0001_m_000000_0
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:04:19 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@190fa6f4
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 16:04:20 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local722503863_0001 running in uber mode : false
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(2064) -Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@5ed7303
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:473)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:655)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:239)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:535)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2061)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:808)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 794024; bufvoid = 104857600
2021-02-26 16:04:31 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26191768(104767072); length = 22629/6553600
2021-02-26 16:04:35 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:04:35 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:04:35 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:04:35 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:04:50 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:04:50 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:04:50 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:04:50 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:05:01 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:05:01 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:05:01 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:05:01 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:05:10 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:05:10 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:05:10 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:05:10 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:05:20 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:05:20 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:05:20 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:05:20 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:05:21 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 16:05:21 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 1
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:1
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local65854036_0001
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local65854036_0001
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local65854036_0001_m_000000_0
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16bccea3
2021-02-26 16:05:21 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 16:05:22 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local65854036_0001 running in uber mode : false
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(2064) -Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@5798f113
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:473)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:655)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:152)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:239)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:535)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:2061)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:808)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 157028; bufvoid = 104857600
2021-02-26 16:07:32 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26209932(104839728); length = 4465/6553600
2021-02-26 16:07:52 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 16:07:52 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 16:07:52 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 16:07:52 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 16:07:53 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 16:07:53 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1045986947_0001
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1045986947_0001
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1045986947_0001_m_000000_0
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@22971a0e
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1902:0+888978
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 16:07:53 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 921777; bufvoid = 104857600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188140(104752560); length = 26257/6553600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1045986947_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1045986947_0001_m_000000_0' done.
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1045986947_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=273
		FILE: Number of bytes written=1440411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888978
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6565
		Map output records=6565
		Map output bytes=921777
		Map output materialized bytes=941452
		Input split bytes=98
		Combine input records=0
		Spilled Records=6565
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=315621376
	File Input Format Counters 
		Bytes Read=888978
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1045986947_0001_m_000000_0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1045986947_0001_m_000001_0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4fb92340
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1045986947_0001 running in uber mode : false
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 920864; bufvoid = 104857600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188144(104752576); length = 26253/6553600
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1045986947_0001_m_000001_0 is done. And is in the process of committing
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1045986947_0001_m_000001_0' done.
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1045986947_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=2380994
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777168
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940551
		Input split bytes=98
		Combine input records=0
		Spilled Records=6564
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=421003264
	File Input Format Counters 
		Bytes Read=888190
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1045986947_0001_m_000001_0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local1045986947_0001_r_000000_0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52bcc999
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@456c1623
2021-02-26 16:07:54 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local1045986947_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local1045986947_0001_m_000000_0 decomp: 941448 len: 941452 to MEMORY
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 941448 bytes from map-output for attempt_local1045986947_0001_m_000000_0
2021-02-26 16:07:54 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 941448, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->941448
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local1045986947_0001_m_000001_0 decomp: 940547 len: 940551 to MEMORY
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 940547 bytes from map-output for attempt_local1045986947_0001_m_000001_0
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 940547, inMemoryMapOutputs.size() -> 2, commitMemory -> 941448, usedMemory ->1881995
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 2 sorted segments
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 2 segments left of total size: 1881981 bytes
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 2 segments, 1881995 bytes to disk to satisfy reduce memory limit
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 1881997 bytes from disk
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 1881986 bytes
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 16:07:55 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1045986947_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1045986947_0001_r_000000_0 is allowed to commit now
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1045986947_0001_r_000000_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1045986947_0001_r_000000_0' done.
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1045986947_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3764552
		FILE: Number of bytes written=4262991
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777168
		HDFS: Number of bytes written=160440
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=116
		Reduce shuffle bytes=1882003
		Reduce input records=13129
		Reduce output records=13129
		Spilled Records=13129
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=421003264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=160440
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local1045986947_0001_r_000000_0
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local1045986947_0001 completed successfully
2021-02-26 16:07:55 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=3765313
		FILE: Number of bytes written=8084396
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4443314
		HDFS: Number of bytes written=160440
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13130
		Map output records=13129
		Map output bytes=1842641
		Map output materialized bytes=1882003
		Input split bytes=196
		Combine input records=0
		Combine output records=0
		Reduce input groups=116
		Reduce shuffle bytes=1882003
		Reduce input records=13129
		Reduce output records=13129
		Spilled Records=26258
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1157627904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1777168
	File Output Format Counters 
		Bytes Written=160440
2021-02-26 16:12:31 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:12:31 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:12:31 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:12:31 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:12:31 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:13:38 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:13:38 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:13:38 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:13:38 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:13:38 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:14:02 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:14:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:14:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:14:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:14:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:02 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:16:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:02 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:20 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:16:20 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:20 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:20 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:16:20 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:23:45 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:23:45 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:23:45 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:23:45 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:23:45 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:24:56 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 16:24:56 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:24:56 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:24:56 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 16:24:56 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 17:33:03 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 17:33:03 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 17:33:03 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 17:33:03 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 17:33:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 17:33:03 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 17:33:03 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 17:33:03 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1668574165_0001
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1668574165_0001
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1668574165_0001_m_000000_0
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@68218b9c
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1902:0+888978
2021-02-26 17:33:04 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1668574165_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:33:04 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1668574165_0001_m_000000_0 is allowed to commit now
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1668574165_0001_m_000000_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1668574165_0001_m_000000_0' done.
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1668574165_0001_m_000000_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=273
		FILE: Number of bytes written=498554
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888978
		HDFS: Number of bytes written=81791
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=6565
		Map output records=6565
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=210763776
	File Input Format Counters 
		Bytes Read=888978
	File Output Format Counters 
		Bytes Written=81791
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1668574165_0001_m_000000_0
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1668574165_0001_m_000001_0
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37238b01
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1668574165_0001 running in uber mode : false
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1668574165_0001_m_000001_0 is done. And is in the process of committing
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1668574165_0001_m_000001_0 is allowed to commit now
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1668574165_0001_m_000001_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1668574165_0001_m_000001_0' done.
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1668574165_0001_m_000001_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=498554
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777168
		HDFS: Number of bytes written=163319
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=210763776
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=81528
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1668574165_0001_m_000001_0
2021-02-26 17:33:05 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 17:33:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local1668574165_0001 completed successfully
2021-02-26 17:33:06 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 20
	File System Counters
		FILE: Number of bytes read=761
		FILE: Number of bytes written=997108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2666146
		HDFS: Number of bytes written=245110
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=13130
		Map output records=13129
		Input split bytes=196
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=421527552
	File Input Format Counters 
		Bytes Read=1777168
	File Output Format Counters 
		Bytes Written=163319
2021-02-26 17:39:26 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 17:39:26 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 17:39:26 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 17:39:26 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 17:39:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 17:39:27 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local1167269060_0001
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local1167269060_0001
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1167269060_0001_m_000000_0
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e7a440f
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1902:0+888978
2021-02-26 17:39:27 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 17:39:27 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1167269060_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1167269060_0001_m_000000_0 is allowed to commit now
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1167269060_0001_m_000000_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1167269060_0001_m_000000_0' done.
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1167269060_0001_m_000000_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=273
		FILE: Number of bytes written=498554
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888978
		HDFS: Number of bytes written=81791
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=6565
		Map output records=6565
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=210763776
	File Input Format Counters 
		Bytes Read=888978
	File Output Format Counters 
		Bytes Written=81791
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1167269060_0001_m_000000_0
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local1167269060_0001_m_000001_0
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@249e8f84
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/GlobalSort/1901:0+888190
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local1167269060_0001_m_000001_0 is done. And is in the process of committing
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local1167269060_0001_m_000001_0 is allowed to commit now
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local1167269060_0001_m_000001_0' to hdfs://node1:9000/GlobalSort_out
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local1167269060_0001_m_000001_0' done.
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local1167269060_0001_m_000001_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=498554
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777168
		HDFS: Number of bytes written=163319
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=210763776
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=81528
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local1167269060_0001_m_000001_0
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local1167269060_0001 running in uber mode : false
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local1167269060_0001 completed successfully
2021-02-26 17:39:28 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 20
	File System Counters
		FILE: Number of bytes read=761
		FILE: Number of bytes written=997108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2666146
		HDFS: Number of bytes written=245110
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=13130
		Map output records=13129
		Input split bytes=196
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=421527552
	File Input Format Counters 
		Bytes Read=1777168
	File Output Format Counters 
		Bytes Written=163319
2021-02-26 17:39:55 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 17:39:55 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 17:39:55 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 17:39:55 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 17:39:55 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:24:57 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 18:24:57 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 18:24:57 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 18:24:57 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 18:25:14 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 18:25:14 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 18:25:14 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 18:25:14 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 18:25:15 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 18:25:15 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local305172126_0001
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local305172126_0001
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local305172126_0001_m_000000_0
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@69c0b3de
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/ncdc/input/1902:0+888978
2021-02-26 18:25:15 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 18:25:15 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local305172126_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local305172126_0001_m_000000_0 is allowed to commit now
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local305172126_0001_m_000000_0' to hdfs://node1:9000/ncdc/sfoutput
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local305172126_0001_m_000000_0' done.
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local305172126_0001_m_000000_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=273
		FILE: Number of bytes written=496134
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=888978
		HDFS: Number of bytes written=81791
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=6565
		Map output records=6565
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=209715200
	File Input Format Counters 
		Bytes Read=888978
	File Output Format Counters 
		Bytes Written=81791
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local305172126_0001_m_000000_0
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local305172126_0001_m_000001_0
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@138dbd71
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/ncdc/input/1901:0+888190
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local305172126_0001 running in uber mode : false
2021-02-26 18:25:16 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 0%
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local305172126_0001_m_000001_0 is done. And is in the process of committing
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local305172126_0001_m_000001_0 is allowed to commit now
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local305172126_0001_m_000001_0' to hdfs://node1:9000/ncdc/sfoutput
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local305172126_0001_m_000001_0' done.
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local305172126_0001_m_000001_0: Counters: 20
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=496134
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777168
		HDFS: Number of bytes written=163319
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=6565
		Map output records=6564
		Input split bytes=98
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=209715200
	File Input Format Counters 
		Bytes Read=888190
	File Output Format Counters 
		Bytes Written=81528
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local305172126_0001_m_000001_0
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local305172126_0001 completed successfully
2021-02-26 18:25:17 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 20
	File System Counters
		FILE: Number of bytes read=761
		FILE: Number of bytes written=992268
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2666146
		HDFS: Number of bytes written=245110
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=13130
		Map output records=13129
		Input split bytes=196
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=419430400
	File Input Format Counters 
		Bytes Read=1777168
	File Output Format Counters 
		Bytes Written=163319
2021-02-26 18:26:32 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 18:26:32 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 18:26:32 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:26:32 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:26:32 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:26:32 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.mapreduce.lib.partition.InputSampler -InputSampler.java(319) -Using 1370 samples
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 18:26:33 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 18:26:33 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 18:26:33 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 18:26:33 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local676251295_0001
2021-02-26 18:26:33 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(200) -Creating symlink: \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335194031\_partition.lst <- H:\code_DT\MR_Demo/_partition.lst
2021-02-26 18:26:34 [ WARN] - org.apache.hadoop.fs.FileUtil -FileUtil.java(1075) -Command 'D:\hadoop\bin\winutils.exe symlink H:\code_DT\MR_Demo\_partition.lst \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335194031\_partition.lst' failed 1 with: CreateSymbolicLink error (1314): ???????????



2021-02-26 18:26:34 [ WARN] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(202) -Failed to create symlink: \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335194031\_partition.lst <- H:\code_DT\MR_Demo/_partition.lst
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(164) -Localized hdfs://node1:9000/user/85094/_partition.lst as file:/opt/bigdata/hadoop-2.7.3/tmpdata/mapred/local/1614335194031/_partition.lst
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local676251295_0001
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:26:34 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 18:26:34 [ WARN] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(590) -job_local676251295_0001
org.apache.hadoop.security.AccessControlException: Permission denied: user=85094, access=WRITE, inode="/ncdc/totalorder/_temporary/0":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2421)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2395)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1325)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1339)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1314)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2275)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:355)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:541)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=85094, access=WRITE, inode="/ncdc/totalorder/_temporary/0":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:292)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:213)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1728)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1712)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1695)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:71)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3896)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:984)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:622)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy9.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy10.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2419)
	... 9 more
2021-02-26 18:26:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local676251295_0001 running in uber mode : false
2021-02-26 18:26:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 0% reduce 0%
2021-02-26 18:26:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1660) -Job job_local676251295_0001 failed with state FAILED due to: NA
2021-02-26 18:26:35 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 0
2021-02-26 18:27:00 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 18:27:00 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 18:27:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:27:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:27:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:27:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:27:01 [ INFO] - org.apache.hadoop.mapreduce.lib.partition.InputSampler -InputSampler.java(319) -Using 1312 samples
2021-02-26 18:27:01 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(153) -Got brand-new compressor [.deflate]
2021-02-26 18:27:01 [ INFO] - org.apache.commons.beanutils.FluentPropertyBeanIntrospector -FluentPropertyBeanIntrospector.java(147) -Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2021-02-26 18:27:01 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsConfig -MetricsConfig.java(134) -Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-02-26 18:27:01 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(374) -Scheduled Metric snapshot period at 10 second(s).
2021-02-26 18:27:01 [ INFO] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(191) -JobTracker metrics system started
2021-02-26 18:27:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(147) -Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-02-26 18:27:02 [ WARN] - org.apache.hadoop.mapreduce.JobResourceUploader -JobResourceUploader.java(480) -No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.input.FileInputFormat -FileInputFormat.java(292) -Total input files to process : 2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(202) -number of splits:2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(298) -Submitting tokens for job: job_local586181471_0001
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.JobSubmitter -JobSubmitter.java(299) -Executing with tokens: []
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(200) -Creating symlink: \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335222246\_partition.lst <- H:\code_DT\MR_Demo/_partition.lst
2021-02-26 18:27:02 [ WARN] - org.apache.hadoop.fs.FileUtil -FileUtil.java(1075) -Command 'D:\hadoop\bin\winutils.exe symlink H:\code_DT\MR_Demo\_partition.lst \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335222246\_partition.lst' failed 1 with: CreateSymbolicLink error (1314): ???????????



2021-02-26 18:27:02 [ WARN] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(202) -Failed to create symlink: \opt\bigdata\hadoop-2.7.3\tmpdata\mapred\local\1614335222246\_partition.lst <- H:\code_DT\MR_Demo/_partition.lst
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalDistributedCacheManager -LocalDistributedCacheManager.java(164) -Localized hdfs://node1:9000/user/root/_partition.lst as file:/opt/bigdata/hadoop-2.7.3/tmpdata/mapred/local/1614335222246/_partition.lst
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1574) -The url to track the job: http://localhost:8080/
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1619) -Running job: job_local586181471_0001
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(501) -OutputCommitter set in config null
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(519) -OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for map tasks
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local586181471_0001_m_000000_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@391d8b94
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/ncdc/sfoutput/part-m-00000:0+81791
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 921777; bufvoid = 104857600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188140(104752560); length = 26257/6553600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local586181471_0001_m_000000_0 is done. And is in the process of committing
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local586181471_0001_m_000000_0' done.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local586181471_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=295
		FILE: Number of bytes written=1440242
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=245462
		HDFS: Number of bytes written=176
		HDFS: Number of read operations=26
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=6565
		Map output records=6565
		Map output bytes=921777
		Map output materialized bytes=941464
		Input split bytes=109
		Combine input records=0
		Spilled Records=6565
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=319291392
	File Input Format Counters 
		Bytes Read=81791
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local586181471_0001_m_000000_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(252) -Starting task: attempt_local586181471_0001_m_000001_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@580f750d
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(768) -Processing split: hdfs://node1:9000/ncdc/sfoutput/part-m-00001:0+81528
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1219) -(EQUATOR) 0 kvi 26214396(104857584)
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1012) -mapreduce.task.io.sort.mb: 100
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1013) -soft limit at 83886080
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1014) -bufstart = 0; bufvoid = 104857600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1015) -kvstart = 26214396; length = 6553600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(409) -Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1476) -Starting flush of map output
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1498) -Spilling map output
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1499) -bufstart = 0; bufend = 920864; bufvoid = 104857600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1501) -kvstart = 26214396(104857584); kvend = 26188144(104752576); length = 26253/6553600
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.MapTask -MapTask.java(1696) -Finished spill 0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local586181471_0001_m_000001_0 is done. And is in the process of committing
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -map
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local586181471_0001_m_000001_0' done.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local586181471_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=532
		FILE: Number of bytes written=2380885
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=327166
		HDFS: Number of bytes written=176
		HDFS: Number of read operations=31
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=6564
		Map output records=6564
		Map output bytes=920864
		Map output materialized bytes=940563
		Input split bytes=109
		Combine input records=0
		Spilled Records=6564
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=424673280
	File Input Format Counters 
		Bytes Read=81528
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(277) -Finishing task: attempt_local586181471_0001_m_000001_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -map task executor complete.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(478) -Waiting for reduce tasks
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local586181471_0001_r_000000_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64965159
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@55441d09
2021-02-26 18:27:02 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local586181471_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local586181471_0001_m_000001_0 decomp: 278845 len: 278849 to MEMORY
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 278845 bytes from map-output for attempt_local586181471_0001_m_000001_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 278845, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->278845
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#1 about to shuffle output of map attempt_local586181471_0001_m_000000_0 decomp: 297407 len: 297411 to MEMORY
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 297407 bytes from map-output for attempt_local586181471_0001_m_000000_0
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 297407, inMemoryMapOutputs.size() -> 2, commitMemory -> 278845, usedMemory ->576252
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 2 sorted segments
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 2 segments left of total size: 576238 bytes
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 2 segments, 576252 bytes to disk to satisfy reduce memory limit
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 576254 bytes from disk
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 576243 bytes
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:02 [ INFO] - org.apache.hadoop.conf.Configuration.deprecation -Configuration.java(1394) -mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local586181471_0001_r_000000_0 is done. And is in the process of committing
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local586181471_0001_r_000000_0 is allowed to commit now
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local586181471_0001_r_000000_0' to hdfs://node1:9000/ncdc/totalorder
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local586181471_0001_r_000000_0' done.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local586181471_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1161390
		FILE: Number of bytes written=2957139
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=327166
		HDFS: Number of bytes written=49963
		HDFS: Number of read operations=36
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=56
		Reduce shuffle bytes=576260
		Reduce input records=4016
		Reduce output records=4016
		Spilled Records=4016
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=424673280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=49787
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local586181471_0001_r_000000_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local586181471_0001_r_000001_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2cc5ad4e
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6c7dfecb
2021-02-26 18:27:03 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local586181471_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local586181471_0001_m_000001_0 decomp: 276935 len: 276939 to MEMORY
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 276935 bytes from map-output for attempt_local586181471_0001_m_000001_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 276935, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->276935
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#2 about to shuffle output of map attempt_local586181471_0001_m_000000_0 decomp: 369936 len: 369940 to MEMORY
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 369936 bytes from map-output for attempt_local586181471_0001_m_000000_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 369936, inMemoryMapOutputs.size() -> 2, commitMemory -> 276935, usedMemory ->646871
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 2 sorted segments
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 2 segments left of total size: 646857 bytes
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 2 segments, 646871 bytes to disk to satisfy reduce memory limit
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 646873 bytes from disk
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 646862 bytes
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local586181471_0001_r_000001_0 is done. And is in the process of committing
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local586181471_0001_r_000001_0 is allowed to commit now
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local586181471_0001_r_000001_0' to hdfs://node1:9000/ncdc/totalorder
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local586181471_0001_r_000001_0' done.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local586181471_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=2463486
		FILE: Number of bytes written=3604012
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=327166
		HDFS: Number of bytes written=105465
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=17
		Reduce shuffle bytes=646879
		Reduce input records=4513
		Reduce output records=4513
		Spilled Records=4513
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=424673280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=55502
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local586181471_0001_r_000001_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(330) -Starting task: attempt_local586181471_0001_r_000002_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(141) -File Output Committer Algorithm version is 2
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(156) -FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.yarn.util.ProcfsBasedProcessTree -ProcfsBasedProcessTree.java(178) -ProcfsBasedProcessTree currently is supported only on Linux.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(625) - Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70a93fd2
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.ReduceTask -ReduceTask.java(363) -Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73a10caa
2021-02-26 18:27:03 [ WARN] - org.apache.hadoop.metrics2.impl.MetricsSystemImpl -MetricsSystemImpl.java(151) -JobTracker metrics system already initialized!
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(208) -MergerManager: memoryLimit=2646448384, maxSingleShuffleLimit=661612096, mergeThreshold=1746656000, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(61) -attempt_local586181471_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#3 about to shuffle output of map attempt_local586181471_0001_m_000001_0 decomp: 384771 len: 384775 to MEMORY
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 384771 bytes from map-output for attempt_local586181471_0001_m_000001_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 384771, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->384771
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.LocalFetcher -LocalFetcher.java(145) -localfetcher#3 about to shuffle output of map attempt_local586181471_0001_m_000000_0 decomp: 274109 len: 274113 to MEMORY
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput -InMemoryMapOutput.java(94) -Read 274109 bytes from map-output for attempt_local586181471_0001_m_000000_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(323) -closeInMemoryFile -> map-output of size: 274109, inMemoryMapOutputs.size() -> 2, commitMemory -> 384771, usedMemory ->658880
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.EventFetcher -EventFetcher.java(76) -EventFetcher is interrupted.. Returning
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(695) -finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 2 sorted segments
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 2 segments left of total size: 658866 bytes
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(762) -Merged 2 segments, 658880 bytes to disk to satisfy reduce memory limit
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(792) -Merging 1 files, 658882 bytes from disk
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl -MergeManagerImpl.java(807) -Merging 0 segments, 0 bytes from memory into reduce
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(606) -Merging 1 sorted segments
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Merger -Merger.java(705) -Down to the last merge-pass, with 1 segments left of total size: 658871 bytes
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1232) -Task:attempt_local586181471_0001_r_000002_0 is done. And is in the process of committing
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -2 / 2 copied.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1409) -Task attempt_local586181471_0001_r_000002_0 is allowed to commit now
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -FileOutputCommitter.java(606) -Saved output of task 'attempt_local586181471_0001_r_000002_0' to hdfs://node1:9000/ncdc/totalorder
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(628) -reduce > reduce
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1368) -Task 'attempt_local586181471_0001_r_000002_0' done.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.Task -Task.java(1264) -Final Counters for attempt_local586181471_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3781416
		FILE: Number of bytes written=4262894
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=327166
		HDFS: Number of bytes written=161120
		HDFS: Number of read operations=46
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=9
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=43
		Reduce shuffle bytes=658888
		Reduce input records=4600
		Reduce output records=4600
		Spilled Records=4600
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=424673280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=55655
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(353) -Finishing task: attempt_local586181471_0001_r_000002_0
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapred.LocalJobRunner -LocalJobRunner.java(486) -reduce task executor complete.
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1640) -Job job_local586181471_0001 running in uber mode : false
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1647) - map 100% reduce 100%
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1658) -Job job_local586181471_0001 completed successfully
2021-02-26 18:27:03 [ INFO] - org.apache.hadoop.mapreduce.Job -Job.java(1665) -Counters: 35
	File System Counters
		FILE: Number of bytes read=7407119
		FILE: Number of bytes written=14645172
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1554126
		HDFS: Number of bytes written=316900
		HDFS: Number of read operations=180
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=27
	Map-Reduce Framework
		Map input records=13129
		Map output records=13129
		Map output bytes=1842641
		Map output materialized bytes=1882027
		Input split bytes=218
		Combine input records=0
		Combine output records=0
		Reduce input groups=116
		Reduce shuffle bytes=1882027
		Reduce input records=13129
		Reduce output records=13129
		Spilled Records=26258
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2017984512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=163319
	File Output Format Counters 
		Bytes Written=160944
2021-02-26 18:28:00 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 18:28:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:00 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:50 [ WARN] - org.apache.hadoop.io.compress.zlib.ZlibFactory -ZlibFactory.java(61) -Failed to load/initialize native-zlib library
2021-02-26 18:28:50 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:50 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:50 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
2021-02-26 18:28:50 [ INFO] - org.apache.hadoop.io.compress.CodecPool -CodecPool.java(184) -Got brand-new decompressor [.deflate]
